# -*- coding: utf-8 -*-
"""Prediksi_Stroke.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i66vN6kz-bdPdoaOHG3paLNroUHC7xQ1

# **Capstone Project SIB Dicoding - Tim C22-083**

#### **Anggota Tim :**
- M284X0684 - Imam Arief Al Baihaqy
- M123Y0195 - Rosyiidah Hasnaa
- M515Y1092 - Erin Nur Fatimah
- M180X0305 - Nikolas Edo

#### **Tema yang dipilih :**
Solusi Terkait Kesehatan dan Kesejahteraan Lingkungan


#### **Judul Proyek :**
Sistem Prediksi Penyakit Stroke Berbasis Machine Learning

#### **Dataset :**
[Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)

# **Data Loading**
"""

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import os
import pickle

# %matplotlib inline

from google.colab import drive
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

drive.mount('/content/drive')

# Memuat dan menampilkan dataframe
csv_loc = 'drive/MyDrive/Dataset/healthcare-dataset-stroke-data.csv'
stroke_data = pd.read_csv(csv_loc)

stroke_data

"""Didapatkan informasi bahwa terdapat 5.110 records dan 12 kolom yaitu: id, gender, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, smoking_status, dan stroke. Kolom "id" tidak akan digunakan dalam pengembangan sistem prediksi, maka akan dihapus pada tahap Data Preprocessing. Dan terdapat missing value berupa nilai NaN pada kolom "bmi", maka hal ini akan ditangani pada tahap EDA - Menangani Missing Value.

# **EDA - Deskripsi Variabel**

- id: Unique Identifier
- gender: Jenis kelamin pengguna (Male, Female, Other)
- age: Umur pengguna
- hypertension: Nilai "0" menunjukkan pengguna tidak memiliki tekanan darah tinggi, nilai "1" menunjukkan pengguna memiliki tekanan darah tinggi.
- heart_disease: Nilai "0" menunjukkan pengguna tidak memiliki penyakit jantung, nilai "1" menunjukkan pengguna memiliki penyakit jantung.
- ever_married: Status menikah yang ditunjukkan dengan nilai "Yes" dan "No".
- work_type: Jenis pekerjaan yang ditunjukkan dengan masih anak-anak (children), PNS (Govt_jov), Tidak pernah bekerja (Never_worked), swasta (Private), dan wiraswasta (Self-employed).
- Residence_type: Lingkungan tempat tinggal apakah di pedesaan (Rural) atau di perkotaan (Urban).
- avg_glucose_level: Kadar glukosa rata-rata dalam darah.
- bmi: Indeks massa tubuh atau ukuran berat badan pengguna.
- smoking_status: Status merokok pengguna, apakah dahulu merupakan seorang perokok (formerly smoked), tidak pernah merokok (never smoked), saat ini seorang perokok (smokes), atau tidak diketahui (unknown).
- stroke: Nilai "0" menunjukkan pengguna tidak teridentifikasi memiliki resiko stroke, nilai "1" menunjukkan pengguna teridentifikasi memiliki resiko stroke.
"""

# Mengecek informasi pada dataset
stroke_data.info()

"""Dari output diatas dapat diketahui bahwa:
-	Terdapat 4 kolom numerik dengan tipe int64, yaitu: id, hypertension, heart_disease, dan stroke. 4 kolom ini nantinya akan masuk kedalam categorical features karena hanya memiliki dua nilai yaitu TRUE dan False.
-	Terdapat 3 kolom numerik dengan tipe data float64, yaitu: age, avg_glucose_level, dan bmi.
- Terdapat 5 kolom dengan tipe object, yaitu: gender, ever_married, work_type, Residence_type, dan smoking_status. Kolom ini merupakan categorical features (fitur non-numerik).
"""

# Melihat deskripsi statistik data
stroke_data.describe()

"""- Count adalah jumlah sampel pada data.
- Mean adalah nilai rata-rata.
- Std adalah standar deviasi.
- Min yaitu nilai minimum setiap kolom. 
- 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama. 
- 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
- 75% adalah kuartil ketiga.
- Max adalah nilai maksimum.

# **EDA - Menangani Missing Value dan Outliers**
"""

# Mengecek missing value pada dataset
stroke_data.isna().sum()

"""Diketahui terdapat 201 missing value pada kolom "bmi", maka hal ini akan diatasi dengan mengganti nilai missing value dengan nilai mean (rata-rata) berat badan "bmi" untuk mempertahankan distribusi data."""

# Missing value pada fitur "bmi" akan diganti dengan nilai rata-rata berat badan pada fitur "bmi"
stroke_data['bmi'].fillna(stroke_data['bmi'].mean(), inplace=True)

stroke_data

# Melihat outliers pada numerical features "age"
sns.boxplot(x=stroke_data['age'])

# Melihat outliers pada numerical features "avg_glucose_level"
sns.boxplot(x=stroke_data['avg_glucose_level'])

# Melihat outliers pada numerical features "bmi"
sns.boxplot(x=stroke_data['bmi'])

# Menangani outliers pada fitur "bmi"
feature_outliers = ['bmi']

Q1 = stroke_data[feature_outliers].quantile(0.25)
Q3 = stroke_data[feature_outliers].quantile(0.75)
IQR=Q3 - Q1

stroke_data[feature_outliers]=stroke_data[feature_outliers][~((stroke_data[feature_outliers] < (Q1 - 1.5 * IQR))|(stroke_data[feature_outliers] > (Q3 + 1.5 * IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah kita drop outliers
stroke_data.shape

"""# **EDA - Univariate Analysis**

Langkah selanjutnya membagi fitur pada dataset menjadi numerical features dan categorical features.
"""

categoric_features = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke']
numeric_features = ['age', 'avg_glucose_level', 'bmi']

"""## **Categorical Features**
Melakkan analisis terhadap fitur kategori
"""

# Memvisualisasikan categorical features "gender"
plt.figure(figsize=(10, 7))
feature = categoric_features[0]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

"""Dari visualisasi fitur gender diatas terdapat 2 kategori pada fitur gender, secara berurutan dari yang paling banyak yaitu: Female, dan Male. Dari data persentase dapat disimpulkan bahwa lebih dari 50% sampel merupakan perempuan "Female"
"""

# Mengecek jumlah sample pada masing-masing variabel pada fitur "gender"
stroke_data.groupby('gender').agg('count')

"""Diketahui terdapat sample yang terlalu sedikit pada jenis kelamin "Other" di fitur "gender". Maka nantinya akan dilakukan penghapusan terhadap sample "Other" pada tahap Data Preparation."""

# Memvisualisasikan categorical features "hypertension"
plt.figure(figsize=(10, 7))
feature = categoric_features[1]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

# Memvisualisasikan categorical features "heart_disease"
plt.figure(figsize=(10, 7))
feature = categoric_features[2]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

# Memvisualisasikan categorical features "ever_married"
plt.figure(figsize=(10, 7))
feature = categoric_features[3]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

# Memvisualisasikan categorical features "work_type"
plt.figure(figsize=(10, 7))
feature = categoric_features[4]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

# Memvisualisasikan categorical features "Residence_type"
plt.figure(figsize=(10, 7))
feature = categoric_features[5]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

# Memvisualisasikan categorical features "smoking_status"
plt.figure(figsize=(10, 7))
feature = categoric_features[6]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

# Memvisualisasikan categorical features "stroke"
plt.figure(figsize=(10, 7))
feature = categoric_features[7]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

"""## **Numerical Features**"""

# Menampilkan histogram pada masing-masing numerical features
stroke_data[numeric_features].hist(bins=50, figsize=(20, 15))

plt.show()

"""# **EDA - Multivariate Analysis**

## **Categorical Features**
"""

cat_features = stroke_data[categoric_features].columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="stroke", kind="bar", dodge=False, height = 4, aspect = 3,  data=stroke_data, palette="Set3")
  plt.title("Rata-rata 'stroke' relatif terhadap - {}".format(col))

"""## **Numerical Features**

Menampilkan kolerasi antar fitur numerical
"""

# Mengevaluasi skor korelasinya
plt.figure(figsize=(14, 12))
correlation_matrix = stroke_data[numeric_features].corr().round(2)
 
# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title('   Correlation Matrix untuk Fitur Numerik\n', size=25)

"""# **Data Preparation**

Kolom "id" akan dihapus karena tidak dibuthkan dalam membuat sistem prediksi.
"""

stroke_data.drop(['id'], axis=1, inplace=True)

stroke_data

# Mengecek missing value pada dataset
stroke_data.isna().sum()

"""Missing value didapatkan setelah penanganan outliers pada fitur "bmi"."""

# Menangani missing value pada fitur "bmi" diganti dengan nilai rata-rata berat badan
stroke_data['bmi'].fillna(stroke_data['bmi'].mean(), inplace=True)

"""Pada tahap EDA - Univariate Analysis terhadap Categorical Features didapatkan sample "Other" pada fitur "gender" memiliki terlalu sedikit sample. Maka akan dilakukan penghapusan terhadap sample ini."""

# Menghapus sample "Other" pada fitur "gender" karena hanya memiliki sedikit sample
stroke_data.drop(stroke_data[(stroke_data['gender'] == 'Other')].index, inplace=True)

"""## **Encoding Categorical Features**
Pada tahap ini categorical features bertipe object akan diubah menjadi numerical features dengan menggunakan Label Encoder.
"""

stroke_data

stroke_data.info()

labelEnc = LabelEncoder()

gender = labelEnc.fit_transform(stroke_data['gender'])
ever_married = labelEnc.fit_transform(stroke_data['ever_married'])
work_type = labelEnc.fit_transform(stroke_data['work_type'])
Residence_type = labelEnc.fit_transform(stroke_data['Residence_type'])
smoking_status = labelEnc.fit_transform(stroke_data['smoking_status'])

stroke_data['gender']=gender
stroke_data['ever_married']=ever_married
stroke_data['work_type']=work_type
stroke_data['Residence_type']=Residence_type
stroke_data['smoking_status']=smoking_status

stroke_data

"""## **Mengatasi Data yang Tidak Seimbang**"""

# Memvisualisasikan categorical features "stroke"
plt.figure(figsize=(10, 7))
feature = categoric_features[7]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

"""Diketahui pada fitur "stroke" dapat dikatakan memiliki data yang tidak seimbang, hal ini dapat dilihat perbedaan sample yang sangat signifikan antara sample yang tidak terindikasi stroke (0), dan sample yang terindikasi stroke (1). Maka hal ini akan ditangani dengan teknik oversampling menggunakan SMOTE.

SMOTE merupakan salah satu pendekatan untuk mengatasi kumpulan data yang tidak seimbang dengan mengambil sample kelas minoritas secara berlebihan. Pendekatan paling sederhana melibatkan duplikasi contoh di kelas minoritas, meskipun contoh ini tidak menambahkan informasi baru ke model. Sebaliknya, contoh baru dapat disintesis dari contoh yang sudah ada. Ini adalah jenis augmentasi data untuk kelas minoritas dan disebut sebagai Synthetic Minority Oversampling Technique, atau disingkat SMOTE.
"""

X = stroke_data.loc[:, stroke_data.columns != 'stroke']
y = stroke_data['stroke']

smote = SMOTE(sampling_strategy='auto', k_neighbors=1, random_state=78)

X_smote, y_smote = smote.fit_resample(X, y)

stroke_data = pd.concat([pd.DataFrame(X_smote), pd.DataFrame(y_smote)], axis=1)

# Memvisualisasikan categorical features "stroke"
plt.figure(figsize=(10, 7))
feature = categoric_features[7]
count = stroke_data[feature].value_counts()
percent = 100 * stroke_data[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})

print(df)
count.plot(kind='bar');
plt.title(feature, size=20)

"""## **Train-Test-Split**"""

# Membagi dataset menjadi data latih (train) dan data uji (test)
X = stroke_data.drop(['stroke'], axis=1)
y = stroke_data['stroke']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)

# Mengecek jumlah sample pada masing-masing bagian
print(f'Total # of sample in whole dataset : {len(X)}')
print(f'Total # of sample in train dataset : {len(X_train)}')
print(f'Total # of sample in test dataset  : {len(X_test)}')

"""## **Standarisasi**
Digunakan StandardScaler dalam melakukan proses standarisasi fitur dengan mengurangkan mean (nilai rata-rata) kemudian membaginya dengan standar deviasi untuk menggeser distribusi.  StandardScaler menghasilkan distribusi dengan standar deviasi sama dengan 1 dan mean sama dengan 0. Sekitar 68% dari nilai akan berada di antara -1 dan 1.
"""

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# **Menyimpan Scaler Object**
Scaler object disimpan dalam format pickle untuk nantinya digunakan dalam melakukan proses deployment.
"""

! mkdir ML-Models

# Menyimpan scaler object
scaler_path = os.path.join('/content/ML-Models/scaler.pkl')
with open(scaler_path, 'wb') as scaler_file:
  pickle.dump(scaler, scaler_file)

"""# **Model Development**
Dalam mengembangkan model Machine Learning pada proyek ini digunakan 3 algoritma, yang kemudian akan devaluasi performa dari masing-masing algoritma dan menentukan salah satu algoritma yang memiliki hasil terbaik.
"""

# Menyiapkan dataframe untuk analisis menggunakan 3 model algoritma
models = pd.DataFrame(index=['train_f1', 'test_f1'],
                      columns=['K-Nearest Neighbor', 'Decision Tree', 'Random Forest'])

"""## **Model Development dengan K-Nearest Neighbor**"""

knn = KNeighborsClassifier(n_neighbors=2, metric='manhattan')
knn.fit(X_train, y_train)

models.loc['train_f1', 'knn'] = f1_score(y_pred = knn.predict(X_train), y_true=y_train)

print('Train Score :', knn.score(X_train, y_train))
print('Test Score  :', knn.score(X_test, y_test))

"""## **Model Development dengan Decision Tree**"""

dt = DecisionTreeClassifier(criterion='entropy', max_depth=17, min_samples_leaf=2, min_samples_split=7)
dt.fit(X_train, y_train)

models.loc['train_f1', 'dt'] = f1_score(y_pred = dt.predict(X_train), y_true=y_train)

print('Train Score :', dt.score(X_train, y_train))
print('Test Score  :', dt.score(X_test, y_test))

"""## **Model Development dengan Random Forest**"""

rf = RandomForestClassifier(n_estimators=32, max_depth=32, random_state=55, n_jobs=-1)
rf.fit(X_train, y_train)

models.loc['train_f1', 'rf'] = f1_score(y_pred = rf.predict(X_train), y_true=y_train)

print('Train Score :', rf.score(X_train, y_train))
print('Test Score  :', rf.score(X_test, y_test))

"""# **Evaluasi Model**"""

# Buat variabel mse yang isinya adalah dataframe nilai f1 data train dan test pada masing-masing algoritma
f1 = pd.DataFrame(columns=['train', 'test'], index=['K-Nearest Neighbor', 'Decision Tree', 'Random Forest'])
 
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'K-Nearest Neighbor': knn, 'Decision Tree': dt, 'Random Forest': rf}

# Hitung f1 score masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
  f1.loc[name, 'train'] = f1_score(y_true=y_train, y_pred=model.predict(X_train), average='micro') 
  f1.loc[name, 'test'] = f1_score(y_true=y_test, y_pred=model.predict(X_test), average='micro')
 
# Panggil f1
f1

# Menampilkan plot
fig, ax = plt.subplots()
f1.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)
plt.legend(loc=2)

"""Dapat diketahui bahwa model development dengan algoritma Random Forest memiliki akurasi tertinggi dengan nilai akurasi test 96%. Maka algoritma inilah yang akan digunakan untuk proses web deployment.

# **Menyimpan Model dengan Akurasi Terbaik**
Setelah proses pelatihan model, kemudian algoritma Random Forest disimpan dalam format pickle untuk nantinya digunakan dalam proses deployment.
"""

pickle.dump(rf, open('/content/ML-Models/model.pkl', 'wb'))

"""Setelah proses penyimpanan, maka model Machine Learning telah siap untuk dilakukan proses web deployment."""